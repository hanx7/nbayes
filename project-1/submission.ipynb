{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP30027 Machine Learning, 2018 Sem 1\n",
    "-----\n",
    "## Project 1: What is labelled data worth to Naive Bayes?\n",
    "-----\n",
    "###### Student Name: Nico Dinata (770318)\n",
    "###### Python version: 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # mostly for pd.DataFrame.iloc[]\n",
    "import numpy as np                      # solely for np.random\n",
    "import math\n",
    "from collections import defaultdict     # the backbone of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess(filename):\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    \n",
    "    # Handle missing values represented by a \"?\", by removing instances\n",
    "    # where it's present\n",
    "    for i in range(len(df.columns)):\n",
    "        df = df[(df[i].map(str) != \"?\")]\n",
    "    \n",
    "    # Reset index after removing some instances\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Separate dataset into table of attributes and that of the classes\n",
    "    list_attribute = df.iloc[:, :(len(df.columns)-1)]\n",
    "    list_class = df.iloc[:, len(df.columns)-1]\n",
    "\n",
    "    return (list_attribute, list_class)\n",
    "\n",
    "\n",
    "test = preprocess('./test.csv')\n",
    "breast_cancer = preprocess('./data/breast-cancer.csv')\n",
    "car = preprocess('./data/car.csv')\n",
    "hypothyroid = preprocess('./data/hypothyroid.csv')\n",
    "mushroom = preprocess('./data/mushroom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model\n",
    "def train_supervised(dataset):\n",
    "    list_attribute = dataset[0]\n",
    "    list_class     = dataset[1]\n",
    "    \n",
    "    # --------------------------------------------------------------------- #\n",
    "    # Prior probability\n",
    "    \n",
    "    # Count number of instances of each class\n",
    "    classes = defaultdict(int)\n",
    "    for c in list_class:\n",
    "        classes[c] += 1\n",
    "    \n",
    "    # The total number of instances\n",
    "    total_class_count = sum(classes.values())\n",
    "    \n",
    "    # Create a dictionary containing the probabilistic model of the classes\n",
    "    # (prior probability)\n",
    "    prior_probability_model = defaultdict(int)\n",
    "    for k in classes.keys():\n",
    "        prior_probability_model[k] = (classes[k]/total_class_count)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------- #\n",
    "    # Posterior probability\n",
    "        \n",
    "    # Create a dictionary of dictionaries of dictionaries (yikes) as\n",
    "    # representation of instances of data (default 1 for Laplace smoothing)\n",
    "    instances = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: 1)))\n",
    "    \n",
    "    # Set to keep track of the distinct attribute values of each attribute\n",
    "    for j in range(len(list_attribute.columns)):\n",
    "        instances[j][\"attribute_values\"] = set()\n",
    "        \n",
    "    # Count number of instances of a particular attribute value given a\n",
    "    # particular class, while also adding that attribute value to the set\n",
    "    for i in range(len(list_class)):\n",
    "        for j in range(len(list_attribute.columns)):\n",
    "            instances[j][list_class[i]][list_attribute.iloc[i,j]] += 1\n",
    "            instances[j][\"attribute_values\"].add(list_attribute.iloc[i,j])\n",
    "    \n",
    "    # Add 1 to the instances of attribute values the model has never seen before\n",
    "    # for a particular class (Laplace smoothing)\n",
    "    for attrib,v in instances.items():\n",
    "        for attrib_instance in instances[attrib][\"attribute_values\"]:\n",
    "            for c,v2 in v.items():\n",
    "                if (c != \"attribute_values\" and instances[attrib][c][attrib_instance] == 0):\n",
    "                    instances[attrib][c][attrib_instance] = 1\n",
    "    \n",
    "    # Create the probabilistic model of the attribute value instances\n",
    "    posterior_probability_model = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "    for attrib,v in instances.items():\n",
    "        for c,v2 in v.items():\n",
    "            if (c != \"attribute_values\"):\n",
    "                for attrib_value,v3 in v2.items():\n",
    "                    posterior_probability_model[c][attrib][attrib_value] = (v3/sum(v2.values()))\n",
    "    \n",
    "    return (prior_probability_model, posterior_probability_model)\n",
    "\n",
    "\n",
    "model_test = train_supervised(test)\n",
    "model_bc = train_supervised(breast_cancer)\n",
    "model_c = train_supervised(car)\n",
    "model_h = train_supervised(hypothyroid)\n",
    "model_m = train_supervised(mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "def predict_supervised(model, dataset):\n",
    "    list_attribute = dataset[0]\n",
    "    prior_probability_model = model[0]\n",
    "    posterior_probability_model = model[1]\n",
    "    predictions = []\n",
    "    \n",
    "    # For each data instance, generate a score for each class and append the class with\n",
    "    # the highest score to the list of predictions\n",
    "    for i in range(len(list_attribute)):\n",
    "        scores = {}\n",
    "        for c,v in posterior_probability_model.items():\n",
    "            score = math.log(prior_probability_model[c])\n",
    "            for j in range(len(list_attribute.columns)):\n",
    "                score += math.log(posterior_probability_model[c][j][list_attribute.iloc[i,j]])\n",
    "            scores[c] = score\n",
    "\n",
    "        v = list(scores.values())\n",
    "        k = list(scores.keys())\n",
    "        predictions.append(k[v.index(max(v))])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "predictions_test = predict_supervised(model_test, test)\n",
    "predictions_bc = predict_supervised(model_bc, breast_cancer)\n",
    "predictions_c = predict_supervised(model_c, car)\n",
    "predictions_h = predict_supervised(model_h, hypothyroid)\n",
    "predictions_m = predict_supervised(model_m, mushroom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY\n",
      "--------\n",
      "Test: 100.0%\n",
      "Breast cancer: 76.895%\n",
      "Car: 87.153%\n",
      "Hypothyroid: 95.146%\n",
      "Mushroom: 97.697%\n"
     ]
    }
   ],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised(predictions, dataset):\n",
    "    list_class = dataset[1]\n",
    "    \n",
    "    # Count the number of correct/matching predictions\n",
    "    correct = 0\n",
    "    for i in range(len(list_class)):\n",
    "        correct += (predictions[i] == list_class[i])\n",
    "    \n",
    "    # Accuracy percentage\n",
    "    result = 100 * correct/len(list_class)\n",
    "    return round(result,3)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "print(\"--------\")\n",
    "print(\"{} {}{}\".format(\"Test:\", evaluate_supervised(predictions_test, test), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Breast cancer:\", evaluate_supervised(predictions_bc, breast_cancer), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Car:\", evaluate_supervised(predictions_c, car), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Hypothyroid:\", evaluate_supervised(predictions_h, hypothyroid), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Mushroom:\", evaluate_supervised(predictions_m, mushroom), \"%\"))\n",
    "\n",
    "# ACCURACY\n",
    "# --------\n",
    "# Test: 100.0%\n",
    "# Breast cancer: 76.895%\n",
    "# Car: 87.153%\n",
    "# Hypothyroid: 95.146%\n",
    "# Mushroom: 97.697%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build an unsupervised NB model \n",
    "def train_unsupervised(dataset, classes, class_distribution):\n",
    "    list_class = []\n",
    "    \n",
    "    # Assign random class distribution if not given one\n",
    "    if (not class_distribution):    \n",
    "        for i in range(len(dataset)):\n",
    "            class_distribution = {}\n",
    "            rand_dis = np.random.random(len(classes))\n",
    "            rand_dis /= rand_dis.sum()\n",
    "        \n",
    "            for j in range(len(classes)):\n",
    "                class_distribution[classes[j]] = rand_dis[j]\n",
    "            list_class.append(class_distribution)\n",
    "    else:\n",
    "        list_class = class_distribution\n",
    "        \n",
    "\n",
    "    # --------------------------------------------------------------------- #\n",
    "    # Prior probability\n",
    "    \n",
    "    # Count the fractional value of each class\n",
    "    class_dist = defaultdict(int)\n",
    "    for c_dict in list_class:\n",
    "        for c,v in c_dict.items():\n",
    "            class_dist[c] += v\n",
    "    \n",
    "    # The total number of instances\n",
    "    total_class_count = sum(class_dist.values())\n",
    "    \n",
    "    # Create a dictionary containing the probabilistic model of the classes\n",
    "    # (prior probability)\n",
    "    prior_probability_model = defaultdict(int)\n",
    "    for k in class_dist.keys():\n",
    "        prior_probability_model[k] = (class_dist[k]/total_class_count)\n",
    "    \n",
    "\n",
    "    # --------------------------------------------------------------------- #\n",
    "    # Posterior probability\n",
    "    \n",
    "    # Create a dictionary of dictionaries of dictionaries as representation\n",
    "    # of instances of data\n",
    "    instances = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "        \n",
    "    # Count number of instances of a particular attribute value given a\n",
    "    # particular class\n",
    "    for i in range(len(list_class)):\n",
    "        for j in range(len(dataset.columns)):\n",
    "            for c,v in list_class[i].items():\n",
    "                instances[j][c][dataset.iloc[i,j]] += v\n",
    "    \n",
    "    # Create the probabilistic model of the attribute value instances\n",
    "    posterior_probability_model = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "    for attrib,v in instances.items():\n",
    "        for c,v2 in v.items():\n",
    "            for attrib_value,v3 in v2.items():\n",
    "                posterior_probability_model[c][attrib][attrib_value] = (v3/sum(v2.values()))\n",
    "    \n",
    "    return (prior_probability_model, posterior_probability_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised(model, dataset):\n",
    "    prior_probability_model = model[0]\n",
    "    posterior_probability_model = model[1]\n",
    "    new_class_distribution = []\n",
    "    \n",
    "    # For each data instance, generate a score for each class to become a more \"reliable\"\n",
    "    # class distribution in the next iteration\n",
    "    for i in range(len(dataset)):\n",
    "        scores = {}\n",
    "        for c,v in posterior_probability_model.items():\n",
    "#             score = math.log(prior_probability_model[c])\n",
    "            score = prior_probability_model[c]\n",
    "            for j in range(len(dataset.columns)):\n",
    "#                 score += math.log(posterior_probability_model[c][j][dataset.iloc[i,j]])\n",
    "                score *= posterior_probability_model[c][j][dataset.iloc[i,j]]\n",
    "#             scores[c] = math.exp(score)\n",
    "            scores[c] = score\n",
    "        \n",
    "        # Normalise the scores\n",
    "        class_sum = sum(scores.values())\n",
    "        for c,v in scores.items():\n",
    "            scores[c] = v/class_sum\n",
    "        \n",
    "        # Add the new class distribution\n",
    "        new_class_distribution.append(scores)\n",
    "    \n",
    "    return new_class_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the process of training and \"predicting\", to (hopefully) improve the probability estimates \n",
    "def iterate(dataset, classes, init_class_distribution):\n",
    "    predictions = []\n",
    "    model = train_unsupervised(dataset, classes, init_class_distribution)\n",
    "    \n",
    "    # Iterate for 10 times\n",
    "    for i in range(10):\n",
    "        new_class_distribution = predict_unsupervised(model, dataset)\n",
    "        model = train_unsupervised(dataset, classes, new_class_distribution)\n",
    "    \n",
    "    # Choose the most probable class as the \"predicted\" class\n",
    "    for i in range(len(dataset)):\n",
    "        v = list(new_class_distribution[i].values())\n",
    "        k = list(new_class_distribution[i].keys())\n",
    "        predictions.append(k[v.index(max(v))])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "    \n",
    "# predictions_test = iterate(test[0], [\"flu\", \"cold\"], [])\n",
    "predictions_bc = iterate(breast_cancer[0], [\"no-recurrence-events\", \"recurrence-events\"], [])\n",
    "predictions_c = iterate(car[0], [\"acc\", \"unacc\", \"good\", \"vgood\"], [])\n",
    "predictions_h = iterate(hypothyroid[0], [\"hypothyroid\", \"negative\"], [])\n",
    "predictions_m = iterate(mushroom[0], [\"e\", \"p\"], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY\n",
      "--------\n",
      "Breast cancer: 37.906%\n",
      "Car: 32.986%\n",
      "Hypothyroid: 87.249%\n",
      "Mushroom: 24.592%\n"
     ]
    }
   ],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised(predictions, dataset):\n",
    "    list_class = dataset[1]\n",
    "    \n",
    "    # Count the number of correct/matching predictions\n",
    "    correct = 0\n",
    "    for i in range(len(list_class)):\n",
    "        correct += (predictions[i] == list_class[i])\n",
    "    \n",
    "    # Accuracy percentage\n",
    "    result = 100 * correct/len(list_class)\n",
    "    return round(result,3)\n",
    "\n",
    "\n",
    "print(\"ACCURACY\")\n",
    "print(\"--------\")\n",
    "# print(\"{} {}{}\".format(\"Test:\", evaluate_unsupervised(predictions_test, test), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Breast cancer:\", evaluate_unsupervised(predictions_bc, breast_cancer), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Car:\", evaluate_unsupervised(predictions_c, car), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Hypothyroid:\", evaluate_unsupervised(predictions_h, hypothyroid), \"%\"))\n",
    "print(\"{} {}{}\".format(\"Mushroom:\", evaluate_unsupervised(predictions_m, mushroom), \"%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "> Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "\n",
    "After several iterations, it is observed that the learner consistently performs poorly on `car.csv`, while “failing” only sometimes on the other datasets. A notable characteristic of this dataset is its four classes, as opposed to two of the others. Firstly, we should consider that after several iterations to improve the probability estimates, the class distributions generally tend to converge to a particular class, forming a “reliable” prediction of the “correct” class.\n",
    "<br>\n",
    "\n",
    "Taking this into account, because `car.csv` has twice the classes of all the other datasets, it may require more iterations to be able to reliably reach a point where only one of its classes obtain a probability much higher than the rest of the classes (e.g. 0.97, 0.1, 0.1, 0.1); this leads to a somewhat “even” spread of probabilities among all the classes. On the flipside, having only two classes seems to expedite the process of reaching convergence, although there is an exception in `mushroom.csv`. It seems to produce a rather low success rate, a cause for which may be due to its large size (in terms of both instances and attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "> When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "\n",
    "One of the potential factors to the variation in accuracy could be the size of the data (number of instances); the higher the number of instances, the higher the chances of unique, previously-unseen attribute value combinations to appear, and thus the better the quality of the model constructed. It’s worth noting, though, that this is not a guarantee, an observation of which is detailed down below. The fact that Laplace smoothing (used in the supervised context of this project) tends to perform better with larger number of instances (doesn’t alter the probabilities too drastically) also plays a part, giving the overall effect of the learner performing better on larger datasets.\n",
    "<br>\n",
    "\n",
    "A particularly interesting result is the fact that the difference in size between `car.csv` and `hypothyroid.csv` is significantly smaller than that between `hypothyroid.csv` and `mushroom.csv`, and yet the leap in accuracy is much higher between `car.csv` and `hypothyroid.csv`. A potential reason is the different ways the attribute value combinations appear on each dataset, relating to the point mentioned above about them being probabilistic. It may also suggest that there is a “peak” number of instances, beyond which it gives diminishing returns in terms of accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
